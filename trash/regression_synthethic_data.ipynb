{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!!! Fix data structure for features_lst -> interpreted as string \n",
    "# should be list of str elems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: shap in /home/rob/.local/lib/python3.8/site-packages (0.39.0)\n",
      "Requirement already satisfied: scipy in /home/rob/.local/lib/python3.8/site-packages (from shap) (1.6.0)\n",
      "Requirement already satisfied: numba in /home/rob/.local/lib/python3.8/site-packages (from shap) (0.52.0)\n",
      "Requirement already satisfied: pandas in /home/rob/.local/lib/python3.8/site-packages (from shap) (1.2.0)\n",
      "Requirement already satisfied: slicer==0.0.7 in /home/rob/.local/lib/python3.8/site-packages (from shap) (0.0.7)\n",
      "Requirement already satisfied: cloudpickle in /home/rob/.local/lib/python3.8/site-packages (from shap) (1.6.0)\n",
      "Requirement already satisfied: scikit-learn in /home/rob/.local/lib/python3.8/site-packages (from shap) (0.24.0)\n",
      "Requirement already satisfied: numpy in /home/rob/.local/lib/python3.8/site-packages (from shap) (1.19.5)\n",
      "Requirement already satisfied: tqdm>4.25.0 in /home/rob/.local/lib/python3.8/site-packages (from shap) (4.56.0)\n",
      "Requirement already satisfied: setuptools in /home/rob/.local/lib/python3.8/site-packages (from numba->shap) (53.0.0)\n",
      "Requirement already satisfied: llvmlite<0.36,>=0.35.0 in /home/rob/.local/lib/python3.8/site-packages (from numba->shap) (0.35.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/lib/python3/dist-packages (from pandas->shap) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/lib/python3/dist-packages (from pandas->shap) (2.7.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/rob/.local/lib/python3.8/site-packages (from scikit-learn->shap) (1.0.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/rob/.local/lib/python3.8/site-packages (from scikit-learn->shap) (2.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ppscore in /home/rob/.local/lib/python3.8/site-packages (1.2.0)\n",
      "Requirement already satisfied: scikit-learn<1.0.0,>=0.20.2 in /home/rob/.local/lib/python3.8/site-packages (from ppscore) (0.24.0)\n",
      "Requirement already satisfied: pandas<2.0.0,>=1.0.0 in /home/rob/.local/lib/python3.8/site-packages (from ppscore) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/lib/python3/dist-packages (from pandas<2.0.0,>=1.0.0->ppscore) (2.7.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/lib/python3/dist-packages (from pandas<2.0.0,>=1.0.0->ppscore) (2019.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /home/rob/.local/lib/python3.8/site-packages (from pandas<2.0.0,>=1.0.0->ppscore) (1.19.5)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/rob/.local/lib/python3.8/site-packages (from scikit-learn<1.0.0,>=0.20.2->ppscore) (1.6.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/rob/.local/lib/python3.8/site-packages (from scikit-learn<1.0.0,>=0.20.2->ppscore) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/rob/.local/lib/python3.8/site-packages (from scikit-learn<1.0.0,>=0.20.2->ppscore) (1.0.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: xgboost in /home/rob/.local/lib/python3.8/site-packages (1.3.3)\n",
      "Requirement already satisfied: scipy in /home/rob/.local/lib/python3.8/site-packages (from xgboost) (1.6.0)\n",
      "Requirement already satisfied: numpy in /home/rob/.local/lib/python3.8/site-packages (from xgboost) (1.19.5)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# for colab compatibility\n",
    "# !pip install shap\n",
    "# !pip install ppscore\n",
    "# !pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run data_load_wrapper.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rip - bug1: feat_ind refers to local instead of global index ordering in function model_fit\n",
    "# rip - bug2: stats dataframe is off by one for mse_test and train - now we have a shifted column\n",
    "# 0th iteration replaced with full_set\n",
    "#\n",
    "# refactor1: get_metric\n",
    "# refactor2: into class MetaReducer(dataset, imp_types, models) \n",
    "# refactor3: create a \"smart\" calculation execution for feature reduction\n",
    "# we can pool the \"votes\" for feature reduction and only retrain the model once per vote class\n",
    "# (feature to reduce), might save decent amount of time for large datasets \n",
    "# (cases where model training takes significantly longer than importance calculation)\n",
    "# current: retrain the model every time for each {imp_type} - not as important right now, since\n",
    "# model training in the worst case takes 3s, feature importance calculation is the bottleneck\n",
    "\"\"\" \n",
    "dataset - sklearn_dataset object or tuple/list of tuples of (x, y)\n",
    "imp_types - list of importance types\n",
    "supported types: ['gini', 'pimp', 'shap', 'pps', 'pearson', 'spearman', 'kendall']\n",
    "models - list of machine learning models from sklearn lib\n",
    "[which ones? tbd]\n",
    "debug = {False, True} display debug_info into the dataframe\n",
    "return -> dataframe of reduction stats\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange\n",
    "import sklearn.datasets as data\n",
    "import pandas as pd\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn import *\n",
    "from sklearn.feature_selection import *\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.utils import Bunch\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import numpy as np\n",
    "import ppscore as pps\n",
    "from datetime import datetime\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearn_to_df(dataset):\n",
    "    df = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "    y = dataset.target\n",
    "    return df, y\n",
    "\n",
    "def get_feat_imp(imp_type, m, x_train, y_train, random_state):\n",
    "    imp_type_dict = {\n",
    "        'mutual_info' : 'mutual_info_regression(x_train, y_train)',\n",
    "        'f_test' : 'f_regression(x_train, y_train)[0]',       \n",
    "        'gini' : \"m.feature_importances_\",\n",
    "        'pimp' : f\"\"\"permutation_importance(m, x_train, y_train, n_repeats=5, \n",
    "        random_state={random_state}).importances_mean\"\"\",\n",
    "        'shap' : \"abs(shap.TreeExplainer(m).shap_values(x_train).mean(axis=0))\",\n",
    "        \n",
    "        'pps' : \"\"\"(pps.predictors(x_train.join(y_train), \n",
    "                                'target', sorted=False, output='df').model_score\n",
    "                                )\"\"\",\n",
    "        \n",
    "        'pearson' : \"abs(x_train.join(y_train).corr(method='pearson').target[:-1])\",\n",
    "        'spearman': \"abs(x_train.join(y_train).corr(method='spearman').target[:-1])\",\n",
    "        'kendall' : \"abs(x_train.join(y_train).corr(method='kendall').target[:-1])\"\n",
    "    }\n",
    "#     print(eval(imp_type_dict.get(imp_type)))\n",
    "    return eval(imp_type_dict.get(imp_type))\n",
    "\n",
    "def reduce_dataset(x_train, x_test, drop_index):\n",
    "    x_train = x_train.drop(x_train.columns[drop_index], axis=1)\n",
    "    x_test = x_test.drop(x_test.columns[drop_index], axis=1)\n",
    "    return x_train, x_test\n",
    "\n",
    "def eval_reduced(x_train, y_train, x_test, y_test, m, imp_type, \n",
    "                 dataset, dataset_str, random_state, dataset_state):\n",
    "    reduce_stats = []\n",
    "    columns_init = np.array(dataset.feature_names)\n",
    "#     dataset_name = dataset.filename.split('/')[-1]\n",
    "    for i in range(len(x_train.columns)):\n",
    "        mse_train, mse_test, drop_index, feat = model_fit(x_train, y_train, \n",
    "                                                     x_test, y_test, m, imp_type, random_state)\n",
    "        global_index = np.where(columns_init==feat);\n",
    "        global_index = global_index[0][0]\n",
    "        reduce_stats.append((i, global_index, feat, \n",
    "                             mse_train, mse_test, \n",
    "                             # get class name, remove trash\n",
    "                             str(m.__class__).split('.')[-1].replace(\"\\'\", '').strip('>'), \n",
    "                             imp_type, dataset_str, x_train.columns, random_state, dataset_state))\n",
    "        x_train, x_test = reduce_dataset(x_train, x_test, drop_index)\n",
    "    return reduce_stats\n",
    "\n",
    "def model_fit(x_train, y_train, x_test, y_test, m, imp_type, random_state):\n",
    "#     print(x_train.shape, y_train.shape)\n",
    "#     refactor1 into function get_metric(type={train, test})\n",
    "    m.fit(x_train, y_train)\n",
    "    res_train = m.predict(x_train)\n",
    "    res_test = m.predict(x_test)\n",
    "    mse_test = metrics.mean_squared_error(y_test, res_test)\n",
    "    mse_train = metrics.mean_squared_error(y_train, res_train)\n",
    "    # get the index for feature with lowest global feature importance\n",
    "    imp = get_feat_imp(imp_type, m, x_train, y_train, random_state)\n",
    "    argmin_fi_index = imp.argmin()\n",
    "    feat = x_train.columns[argmin_fi_index]\n",
    "    return mse_train, mse_test, argmin_fi_index, feat\n",
    "\n",
    "def eval_reduced_one_shot(x_train, y_train, x_test, y_test, m, imp_type, \n",
    "                 dataset, dataset_str, random_state, dataset_state):\n",
    "    \n",
    "    reduce_stats = []\n",
    "    columns_init = np.array(x_train.columns)\n",
    "    m.set_params(random_state = random_state)\n",
    "    m.fit(x_train, y_train)\n",
    "    fi_scores = get_feat_imp(imp_type, m, x_train, y_train, random_state)\n",
    "#     print(f'imp: {imp_type} \\n model: {m} \\n x_shape: {x_train.shape} \\n y_shape: {y_train.shape}')\n",
    "#     print(f'arr_scores: {fi_scores} \\n shape: {fi_scores.shape}')\n",
    "    \n",
    "    for i in range(len(x_train.columns)):\n",
    "        mse_train, mse_test, drop_index, feat = model_fit_one_shot(x_train, y_train, \n",
    "                                                     x_test, y_test, m, fi_scores, random_state)\n",
    "        global_index = np.where(columns_init==feat);\n",
    "        global_index = global_index[0][0]\n",
    "#         print(global_index)\n",
    "#         print(fi_scores)\n",
    "        reduce_stats.append((i, global_index, feat, \n",
    "                             mse_train, mse_test, \n",
    "                             # get class name, remove trash\n",
    "                             str(m.__class__).split('.')[-1].replace(\"\\'\", '').strip('>'), \n",
    "                             imp_type, dataset_str, x_train.columns, random_state, dataset_state))\n",
    "        x_train, x_test = reduce_dataset(x_train, x_test, drop_index)\n",
    "#         print(f'iter {i}')\n",
    "#         print(f'local_index: {drop_index}')\n",
    "#         print(f'global_index: {global_index}, \\n fi before: \\n {fi_scores}')\n",
    "#         print(fi_scores.shape)\n",
    "        fi_scores = np.array(fi_scores)\n",
    "        fi_scores = np.delete(fi_scores, drop_index)\n",
    "#         print(f'global_index: {global_index}, \\n fi after: \\n {fi_scores}')              \n",
    "    return reduce_stats\n",
    "\n",
    "def model_fit_one_shot(x_train, y_train, x_test, y_test, m, fi_scores, \n",
    "                       random_state):\n",
    "#     print(x_train.shape, y_train.shape)\n",
    "#     refactor1 into function get_metric(type={train, test})\n",
    "    m.set_params(random_state=random_state)\n",
    "    m.fit(x_train, y_train)\n",
    "    res_train = m.predict(x_train)\n",
    "    res_test = m.predict(x_test)\n",
    "    mse_test = metrics.mean_squared_error(y_test, res_test)\n",
    "    mse_train = metrics.mean_squared_error(y_train, res_train)\n",
    "    # get the index for feature with lowest global feature importance\n",
    "    imp = fi_scores\n",
    "    argmin_fi_index = imp.argmin()\n",
    "    \n",
    "    feat = x_train.columns[argmin_fi_index]\n",
    "    return mse_train, mse_test, argmin_fi_index, feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(imp_types, models, datasets, debug=False, random_states=[0], dataset_states=[0]):\n",
    "    results = []\n",
    "    datasets_str = list(datasets.keys())\n",
    "    datasets_data = datasets.items()\n",
    "    random_state = 0\n",
    "    for ds in trange(len(dataset_states), desc='Data state progress'):\n",
    "        dataset_state = dataset_states[ds]\n",
    "        for r in trange(len(random_states), desc='Model random state progress'):\n",
    "            random_state = random_states[r]\n",
    "\n",
    "            for j in trange(len(datasets_str), desc=f'Dataset progress'):\n",
    "                dataset_str = datasets_str[j]\n",
    "                dataset = datasets.get(datasets_str[j])\n",
    "                df, y = sklearn_to_df(dataset)\n",
    "                x_train, x_test = model_selection.train_test_split(df, test_size=0.3, \n",
    "                                                                   random_state=dataset_state)\n",
    "                columns_init = x_train.columns\n",
    "                y_train = pd.DataFrame(y[x_train.index], index=x_train.index, columns=['target'])\n",
    "                y_test = pd.DataFrame(y[x_test.index], index=x_test.index, columns=['target'])\n",
    "\n",
    "                for k in trange(len(models), desc=f'Model progress for dataset {j}'):\n",
    "                    m = models[k]\n",
    "                    m.set_params(random_state=random_state)\n",
    "                    m.fit(x_train, y_train.target)\n",
    "                    res_test = m.predict(x_test)\n",
    "                    res_train = m.predict(x_train)\n",
    "                    mse_test = metrics.mean_squared_error(y_test, res_test)\n",
    "                    mse_train = metrics.mean_squared_error(y_train, res_train)\n",
    "\n",
    "                    for i in trange(len(imp_types), desc=f'Importance type progress for model {k}'):\n",
    "                        if imp_types[i] in ['shap', 'pimp', 'pearson', 'spearman', 'kendall',\n",
    "                                            'pps', 'mutual_info', 'f_test']:\n",
    "                            result = eval_reduced_one_shot(x_train, y_train, x_test, y_test, \n",
    "                                                           m, imp_types[i], dataset, dataset_str, \n",
    "                                                           random_state, dataset_state)\n",
    "                        else:\n",
    "                            result = eval_reduced(x_train, y_train.target, x_test, y_test, \n",
    "                                                  m, imp_types[i], dataset, dataset_str, \n",
    "                                                  random_state, dataset_state)\n",
    "                        results.extend(result)\n",
    "                df_res = pd.DataFrame(results, columns=['iteration', 'feat_ind', 'feat_name',\n",
    "                                                    'mse_train', 'mse_test','model', 'imp_type', \n",
    "                                                    'dataset', 'features_lst', \n",
    "                                                    'random_state', 'data_split'])\n",
    "        # shift features by 1 row, replace 0th iteration with 'full_set'\n",
    "        df_res['dropped_feature'] = df_res['feat_name'].shift(1)\n",
    "        df_res['dropped_feature'] = df_res['dropped_feature'].where(df_res['iteration'] != 0, 'full_set')\n",
    "        if debug==True:\n",
    "            repr_lst = ['iteration', 'dropped_feature', 'feat_ind', 'feat_name',\n",
    "                        'mse_train', 'mse_test','model', 'imp_type', \n",
    "                        'dataset', 'features_lst','random_state', 'data_split']\n",
    "        else:\n",
    "            repr_lst = ['iteration','dropped_feature','mse_train',\n",
    "         'mse_test','model','imp_type', 'dataset', 'random_state', 'data_split']\n",
    "        df_res = df_res[repr_lst]\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coerce_synthethic_datasets(samples, features, percent_informative, random_state):\n",
    "    data, target = make_regression(n_samples=samples, n_features=features, \n",
    "                                       n_informative=int(percent_informative*features),\n",
    "                                       shuffle=False,\n",
    "                                       random_state=random_state\n",
    "                                      )\n",
    "    feature_names = [f'x_{i}' for i in range(features)]\n",
    "    # data, target, feature_names\n",
    "    data_bunch = Bunch(\n",
    "        data=data,\n",
    "        target=target,\n",
    "        feature_names=feature_names,\n",
    "        informative_features=feature_names[:int(percent_informative*features)]\n",
    "                        )\n",
    "    return data_bunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "imp_types = [\n",
    "             'gini',\n",
    "             'mutual_info',\n",
    "             'f_test',\n",
    "             'pimp', \n",
    "#              'shap', \n",
    "             'pearson', \n",
    "             'spearman', \n",
    "             'kendall', \n",
    "             'pps'\n",
    "            ]\n",
    "n_jobs = -1\n",
    "models = [\n",
    "          tree.DecisionTreeRegressor(random_state=0), \n",
    "          ensemble.RandomForestRegressor(random_state=0, n_jobs=n_jobs, verbose=0), \n",
    "          xgboost.XGBRegressor(random_state=0, n_jobs=n_jobs, verbosity=0)\n",
    "         ]\n",
    "\n",
    "random_states = [i for i in range(1)]\n",
    "dataset_states = [i for i in range(1)]\n",
    "\n",
    "features = [10, 100]\n",
    "samples = [10, 100, 1000, 10000]\n",
    "# features = [100]\n",
    "# samples = [10000]\n",
    "synthethic_states = [i for i in range(1)]\n",
    "percent_informative = 0.2\n",
    "\n",
    "tuples = []\n",
    "for i in features:\n",
    "    for j in samples:\n",
    "        if i != j:\n",
    "            for k in synthethic_states:            \n",
    "                tuples.append((i,j,k))\n",
    "datasets = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat, samples, random_seed in tuples:\n",
    "    datasets[f'regr_features_{feat}_samples_{samples}_seed_{random_seed}'] = coerce_synthethic_datasets(samples, feat, 0.2, random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 0\n",
    "imp_types = [\n",
    "             'gini',\n",
    "             'mutual_info',\n",
    "             'f_test',\n",
    "             'pimp', \n",
    "#              'shap', \n",
    "             'pearson', \n",
    "             'spearman', \n",
    "             'kendall', \n",
    "             'pps'\n",
    "            ]\n",
    "\n",
    "imp_type_dict = {\n",
    "        'mutual_info' : 'mutual_info_regression(x_train, y_train)',\n",
    "        'f_test' : 'f_regression(x_train, y_train)[0]',       \n",
    "        'gini' : \"m.feature_importances_\",\n",
    "        'pimp' : f\"\"\"permutation_importance(m, x_train, y_train, n_repeats=5, \n",
    "        random_state={random_state}).importances_mean\"\"\",\n",
    "#         'shap' : \"abs(shap.TreeExplainer(m).shap_values(x_train).mean(axis=0))\",\n",
    "        'pps' : \"\"\"(pps.predictors(x_train.join(y_train), \n",
    "                                'target', sorted=False, output='df').model_score\n",
    "                                )\"\"\", \n",
    "        'pearson' : \"abs(x_train.join(y_train).corr(method='spearman').target[:-1])\",\n",
    "        'spearman': \"abs(x_train.join(y_train).corr(method='spearman').target[:-1])\",\n",
    "        'kendall' : \"abs(x_train.join(y_train).corr(method='kendall').target[:-1])\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_jobs=-1, random_state=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train = make_regression(n_samples=10000, n_features=100, \n",
    "                                       n_informative=2,\n",
    "                                       shuffle=False,\n",
    "                                       random_state=0\n",
    "                                      )\n",
    "x_train = pd.DataFrame(x_train) \n",
    "y_train = pd.DataFrame(y_train)\n",
    "y_train = y_train.rename({0:'target'}, axis=1)\n",
    "\n",
    "m = ensemble.RandomForestRegressor(random_state=0, n_jobs=n_jobs, verbose=0)\n",
    "m.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.1 ms ± 2.3 ms per loop (mean ± std. dev. of 100 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "a = %timeit -o -n1 -r100 eval(imp_type_dict.get('gini'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.01973970397375524,\n",
       " 0.018892546999268234,\n",
       " 0.01948619302129373,\n",
       " 0.019193379004718736,\n",
       " 0.019372512004338205,\n",
       " 0.019454822002444416,\n",
       " 0.021159576019272208,\n",
       " 0.019719153991900384,\n",
       " 0.01990813500015065,\n",
       " 0.019389140012208372,\n",
       " 0.023386665008729324,\n",
       " 0.026463171001523733,\n",
       " 0.021354077995056286,\n",
       " 0.016844339988892898,\n",
       " 0.017138392984634265,\n",
       " 0.019410522014368325,\n",
       " 0.016927669988945127,\n",
       " 0.017465016018832102,\n",
       " 0.016995731013594195,\n",
       " 0.01720411400310695,\n",
       " 0.019750394014408812,\n",
       " 0.016794919996755198,\n",
       " 0.021453108987770975,\n",
       " 0.016894000000320375,\n",
       " 0.016917052009375766,\n",
       " 0.016862019983818755,\n",
       " 0.016678849002346396,\n",
       " 0.016852020024089143,\n",
       " 0.017002342006890103,\n",
       " 0.01689730101497844,\n",
       " 0.01689349001389928,\n",
       " 0.017011921998346224,\n",
       " 0.016845779988216236,\n",
       " 0.016619658999843523,\n",
       " 0.017240083019714803,\n",
       " 0.01700365199940279,\n",
       " 0.016808009997475892,\n",
       " 0.017202513001393527,\n",
       " 0.01713580300565809,\n",
       " 0.016543448000447825,\n",
       " 0.0170553220086731,\n",
       " 0.016718559025321156,\n",
       " 0.016729038004996255,\n",
       " 0.016542687022592872,\n",
       " 0.016534488007891923,\n",
       " 0.01666800898965448,\n",
       " 0.01812682001036592,\n",
       " 0.01670520898187533,\n",
       " 0.016458786994917318,\n",
       " 0.018736046011326835,\n",
       " 0.01710062299389392,\n",
       " 0.0171715629985556,\n",
       " 0.017115491995355114,\n",
       " 0.016980020998744294,\n",
       " 0.0231437329784967,\n",
       " 0.018437783990520984,\n",
       " 0.019200499984435737,\n",
       " 0.019885595014784485,\n",
       " 0.023993120004888624,\n",
       " 0.019478873000480235,\n",
       " 0.020105396979488432,\n",
       " 0.017572085984284058,\n",
       " 0.0172209529846441,\n",
       " 0.01671942899702117,\n",
       " 0.016926330979913473,\n",
       " 0.016492727008881047,\n",
       " 0.016688289993908256,\n",
       " 0.02088658299180679,\n",
       " 0.01544815898523666,\n",
       " 0.01660024799639359,\n",
       " 0.016804309998406097,\n",
       " 0.01939420201233588,\n",
       " 0.016912619990762323,\n",
       " 0.01597912301076576,\n",
       " 0.01703444099985063,\n",
       " 0.01646397798322141,\n",
       " 0.015604610001901165,\n",
       " 0.01680479900096543,\n",
       " 0.01698450100957416,\n",
       " 0.016810770001029596,\n",
       " 0.017036701989127323,\n",
       " 0.02286970999557525,\n",
       " 0.018770397000480443,\n",
       " 0.017387314001098275,\n",
       " 0.021531790000153705,\n",
       " 0.029669996991287917,\n",
       " 0.017365364998113364,\n",
       " 0.018293031986104324,\n",
       " 0.016523187019629404,\n",
       " 0.016789179004263133,\n",
       " 0.01705340199987404,\n",
       " 0.01689143097610213,\n",
       " 0.01665787899401039,\n",
       " 0.016929911012994125,\n",
       " 0.016616437991615385,\n",
       " 0.01639811697532423,\n",
       " 0.017325894004898146,\n",
       " 0.017321924009593204,\n",
       " 0.022036603011656553,\n",
       " 0.016746659006457776]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array(a.all_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_types = [\n",
    "             'gini',\n",
    "            'mutual_info'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing gini, for regr_features_10_samples_100_seed_0\n",
      "18.7 ms ± 3.19 ms per loop (mean ± std. dev. of 100 runs, 1 loop each)\n",
      "executed gini\n",
      "executing mutual_info, for regr_features_10_samples_100_seed_0\n",
      "11 ms ± 1.26 ms per loop (mean ± std. dev. of 100 runs, 1 loop each)\n",
      "executed mutual_info\n",
      "executing gini, for regr_features_10_samples_1000_seed_0\n",
      "17.2 ms ± 770 µs per loop (mean ± std. dev. of 100 runs, 1 loop each)\n",
      "executed gini\n",
      "executing mutual_info, for regr_features_10_samples_1000_seed_0\n",
      "41.1 ms ± 1.42 ms per loop (mean ± std. dev. of 100 runs, 1 loop each)\n",
      "executed mutual_info\n",
      "executing gini, for regr_features_10_samples_10000_seed_0\n",
      "17.4 ms ± 1.23 ms per loop (mean ± std. dev. of 100 runs, 1 loop each)\n",
      "executed gini\n",
      "executing mutual_info, for regr_features_10_samples_10000_seed_0\n",
      "500 ms ± 15.8 ms per loop (mean ± std. dev. of 100 runs, 1 loop each)\n",
      "executed mutual_info\n",
      "executing gini, for regr_features_100_samples_10_seed_0\n",
      "The slowest run took 4.06 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "20.2 ms ± 6.17 ms per loop (mean ± std. dev. of 100 runs, 1 loop each)\n",
      "executed gini\n",
      "executing mutual_info, for regr_features_100_samples_10_seed_0\n",
      "79 ms ± 5.58 ms per loop (mean ± std. dev. of 100 runs, 1 loop each)\n",
      "executed mutual_info\n",
      "executing gini, for regr_features_100_samples_1000_seed_0\n",
      "17.6 ms ± 2.1 ms per loop (mean ± std. dev. of 100 runs, 1 loop each)\n",
      "executed gini\n",
      "executing mutual_info, for regr_features_100_samples_1000_seed_0\n",
      "421 ms ± 16.5 ms per loop (mean ± std. dev. of 100 runs, 1 loop each)\n",
      "executed mutual_info\n",
      "executing gini, for regr_features_100_samples_10000_seed_0\n",
      "19 ms ± 3.68 ms per loop (mean ± std. dev. of 100 runs, 1 loop each)\n",
      "executed gini\n",
      "executing mutual_info, for regr_features_100_samples_10000_seed_0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-394ef5a13521>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'executing {i}, for {k}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mtime_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timeit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-o -n1 -r100 eval(imp_type_dict.get(i))'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mtime_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_lst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m#%timeit -o -n1 -r100 eval(imp_type_dict.get('gini'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2315\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2317\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2318\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1162\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1164\u001b[0;31m         \u001b[0mall_runs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1165\u001b[0m         \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_runs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m         \u001b[0mworst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_runs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/timeit.py\u001b[0m in \u001b[0;36mrepeat\u001b[0;34m(self, repeat, number)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/feature_selection/_mutual_info.py\u001b[0m in \u001b[0;36mmutual_info_regression\u001b[0;34m(X, y, discrete_features, n_neighbors, copy, random_state)\u001b[0m\n\u001b[1;32m    365\u001b[0m            \u001b[0mof\u001b[0m \u001b[0ma\u001b[0m \u001b[0mRandom\u001b[0m \u001b[0mVector\u001b[0m\u001b[0;31m\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProbl\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mPeredachi\u001b[0m \u001b[0mInf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m23\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1987\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \"\"\"\n\u001b[0;32m--> 367\u001b[0;31m     return _estimate_mi(X, y, discrete_features, False, n_neighbors,\n\u001b[0m\u001b[1;32m    368\u001b[0m                         copy, random_state)\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/feature_selection/_mutual_info.py\u001b[0m in \u001b[0;36m_estimate_mi\u001b[0;34m(X, y, discrete_features, discrete_target, n_neighbors, copy, random_state)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1e-10\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m     mi = [_compute_mi(x, y, discrete_feature, discrete_target, n_neighbors) for\n\u001b[0m\u001b[1;32m    286\u001b[0m           x, discrete_feature in zip(_iterate_columns(X), discrete_mask)]\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/feature_selection/_mutual_info.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1e-10\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m     mi = [_compute_mi(x, y, discrete_feature, discrete_target, n_neighbors) for\n\u001b[0m\u001b[1;32m    286\u001b[0m           x, discrete_feature in zip(_iterate_columns(X), discrete_mask)]\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/feature_selection/_mutual_info.py\u001b[0m in \u001b[0;36m_compute_mi\u001b[0;34m(x, y, x_discrete, y_discrete, n_neighbors)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_compute_mi_cd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_compute_mi_cc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/feature_selection/_mutual_info.py\u001b[0m in \u001b[0;36m_compute_mi_cc\u001b[0;34m(x, y, n_neighbors)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mradius\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0mradius\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnextafter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mradius\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m                 \u001b[0mparallel_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"prefer\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"threads\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             chunked_results = Parallel(n_jobs, **parallel_kwargs)(\n\u001b[0m\u001b[1;32m    723\u001b[0m                 delayed(_tree_query_parallel_helper)(\n\u001b[1;32m    724\u001b[0m                     self._tree, X[s], n_neighbors, return_distance)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36m_tree_query_parallel_helper\u001b[0;34m(tree, *args, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[0munder\u001b[0m \u001b[0mPyPy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m     \"\"\"\n\u001b[0;32m--> 547\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %%time`\n",
    "for k in datasets.keys():\n",
    "    for i in imp_types:\n",
    "        x_train = datasets[k].data\n",
    "        y_train = datasets[k].target\n",
    "        print(f'executing {i}, for {k}')\n",
    "        time_lst = %timeit -o -n1 -r100 eval(imp_type_dict.get(i))\n",
    "        time_arr = np.array(time_lst)\n",
    "        #%timeit -o -n1 -r100 eval(imp_type_dict.get('gini'))\n",
    "        print(f'executed {i}')\n",
    "#         print(f'mean exec_time = {time_arr.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset = datasets['regr_features_100_samples_10000_seed_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6517bc95ff404ec1a58a9eb5ce103829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Data state progress:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94454aaf4c124c7693d2ecc7c41c5030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Model random state progress:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37e3f265119146e2b926c9f1a879c574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dataset progress:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc5740d7de504eaba3811f461785e0ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Model progress for dataset 0:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3c20da60f3a4d89bc7a3b68f9a843b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Importance type progress for model 0:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be0878244118452d9e0a705c27bc0727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Importance type progress for model 1:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "540ecc2426204d9fa519d1221eaa35ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Importance type progress for model 2:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-9254718bccfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m df_res = get_stats(imp_types, models, datasets, debug=True, \n\u001b[0m\u001b[1;32m      2\u001b[0m                    random_states=random_states, dataset_states=dataset_states)\n",
      "\u001b[0;32m<ipython-input-7-77467061b124>\u001b[0m in \u001b[0;36mget_stats\u001b[0;34m(imp_types, models, datasets, debug, random_states, dataset_states)\u001b[0m\n\u001b[1;32m     31\u001b[0m                         if imp_types[i] in ['shap', 'pimp', 'pearson', 'spearman', 'kendall',\n\u001b[1;32m     32\u001b[0m                                             'pps', 'mutual_info', 'f_test']:\n\u001b[0;32m---> 33\u001b[0;31m                             result = eval_reduced_one_shot(x_train, y_train, x_test, y_test, \n\u001b[0m\u001b[1;32m     34\u001b[0m                                                            \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimp_types\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_str\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                                                            random_state, dataset_state)\n",
      "\u001b[0;32m<ipython-input-6-b20f1cad7db2>\u001b[0m in \u001b[0;36meval_reduced_one_shot\u001b[0;34m(x_train, y_train, x_test, y_test, m, imp_type, dataset, dataset_str, random_state, dataset_state)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         mse_train, mse_test, drop_index, feat = model_fit_one_shot(x_train, y_train, \n\u001b[0m\u001b[1;32m     76\u001b[0m                                                      x_test, y_test, m, fi_scores, random_state)\n\u001b[1;32m     77\u001b[0m         \u001b[0mglobal_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns_init\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-b20f1cad7db2>\u001b[0m in \u001b[0;36mmodel_fit_one_shot\u001b[0;34m(x_train, y_train, x_test, y_test, m, fi_scores, random_state)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;31m#     refactor1 into function get_metric(type={train, test})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0mres_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mres_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m    595\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'eval_metric'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         self._Booster = train(params, train_dmatrix,\n\u001b[0m\u001b[1;32m    598\u001b[0m                               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_num_boosting_rounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0mBooster\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \"\"\"\n\u001b[0;32m--> 227\u001b[0;31m     bst = _train_internal(params, dtrain,\n\u001b[0m\u001b[1;32m    228\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                           \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1280\u001b[0;31m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[1;32m   1281\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_res = get_stats(imp_types, models, datasets, debug=True, \n",
    "                   random_states=random_states, dataset_states=dataset_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export results to local dir as csv file\n",
    "df_res.to_csv(f'regression_synthethic_{datetime.today().strftime(\"%Y-%b-%d-%H:%M:%S\")}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "\n",
    "# plot = sns.lineplot(x='iteration', y='mse_test', hue='imp_type',\n",
    "#             data=df_res.query('model == \"XGBRegressor\" and dataset == \"diabetes\"')\n",
    "#             )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
