{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "import sklearn.datasets as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run data_load_wrapper.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_glob = glob.glob('./*real_data*csv*')\n",
    "res_glob_names = [val.split('/')[-1] for val in res_glob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./classification_real_data_ds0_9_rs10_small_fixed.csv',\n",
       " './regression_real_data_ds0_9_rs10_small.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_dfs = [f for f in res_glob_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_dfs = [pd.read_csv(f) for f in res_glob_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_full = pd.concat(lst_dfs)\n",
    "df = lst_dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets  = {\n",
    "    'boston' : data.load_boston().feature_names,\n",
    "    'diabetes': data.load_diabetes().feature_names,\n",
    "    'crime' : read_crime().feature_names,\n",
    "    'ames_housing' : read_ames_housing().feature_names,\n",
    "    'wine' : data.load_wine().feature_names,\n",
    "    'breast_cancer': data.load_breast_cancer().feature_names,    \n",
    "    'phishing' : read_phishing().feature_names,\n",
    "    'mushroom' : read_mushroom().feature_names \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_sets(df):\n",
    "    # this is really bad performance wise, but since \n",
    "    # we need inter-record actions we have no choice\n",
    "    # there is proubably a way to optimize this since we process small subarrays\n",
    "    lst = []\n",
    "    start = 0\n",
    "    for i in range(1000):\n",
    "        curr_arr = df.iloc[i]\n",
    "        # at the start of a new experiment move dataset start pointer\n",
    "        if curr_arr.iteration == 0:\n",
    "            start = i\n",
    "        sub_arr = df.iloc[start:i+1]\n",
    "        # grab all dropped features\n",
    "        all_dropped = set(sub_arr.dropped_feature.tolist())\n",
    "        all_dropped.remove('full_set')\n",
    "        \n",
    "        # old stuff\n",
    "        # set_dataset = curr_arr.full_feature_set\n",
    "        # select feature intersection\n",
    "        # set_features = set_all & set_dataset\n",
    "\n",
    "        lst.append(all_dropped)\n",
    "        \n",
    "    feature_arr = pd.Series(lst, name='dropped_feature_set')   \n",
    "    return feature_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clasif_features(df):\n",
    "    cols = ['dataset', 'random_state', 'data_split', 'model', 'imp_type', 'mcc_test']\n",
    "    idx = ['dataset', 'random_state', 'data_split', 'model', 'imp_type']\n",
    "\n",
    "    init_metric = df.query('dropped_feature == \"full_set\"')\n",
    "    init_metric = init_metric.groupby(idx).mcc_test.max()\n",
    "    init_metric = init_metric.rename('init_mcc_test')\n",
    "\n",
    "    # merge into original df\n",
    "    df_full= pd.merge(df, init_metric, on=idx, how='inner')\n",
    "    \n",
    "    cols = ['dataset', 'iteration']\n",
    "    idx = ['dataset']\n",
    "    max_feature_cnt = df[cols]\n",
    "    max_feature_cnt = max_feature_cnt.groupby(idx).max() + 1\n",
    "\n",
    "    max_feature_cnt['f_cnt_10perc'] = np.round((max_feature_cnt.iteration * 0.1)).astype(int)\n",
    "    max_feature_cnt['f_cnt_20perc'] = np.round((max_feature_cnt.iteration * 0.2)).astype(int)\n",
    "    max_feature_cnt['f_cnt_30perc'] = np.round((max_feature_cnt.iteration * 0.3)).astype(int)\n",
    "    max_feature_cnt = max_feature_cnt.rename(columns={'iteration':'max_feature_cnt'})\n",
    "\n",
    "    # merge into original df\n",
    "    df_full = pd.merge(df_full, max_feature_cnt, on=idx, how='inner')\n",
    "    \n",
    "    df_full['mcc_delta'] = df_full.mcc_test - df_full.init_mcc_test\n",
    "    df_full['mcc_perc'] = abs(df_full.mcc_test / df_full.init_mcc_test) -1\n",
    "    df_full['feature_cnt'] = df_full.max_feature_cnt - df_full.iteration\n",
    "    df_full['pp_coef'] =  df_full.mcc_test / df_full.init_mcc_test\n",
    "\n",
    "    # max_perc grouping\n",
    "    grouping = ['dataset', 'random_state', 'data_split', 'model', 'imp_type']\n",
    "\n",
    "    # select all non-base models\n",
    "    max_perc = df_full.query('iteration > 0')\n",
    "    max_perc = max_perc.groupby(grouping).mcc_perc.max()\n",
    "    max_perc = max_perc.rename('max_perc')\n",
    "\n",
    "    df_full = pd.merge(df_full, max_perc, on=grouping, how='inner')\n",
    "    \n",
    "    df_full['feature_dropped'] =  df_full.max_feature_cnt - df_full.feature_cnt\n",
    "    df_full['feature_dropped_perc'] = (1 - (df_full.max_feature_cnt - df_full.feature_dropped) \n",
    "                                   / df_full.max_feature_cnt)\n",
    "    \n",
    "    features_df = pd.DataFrame(datasets.items(), columns=['dataset', 'full_feature_lst'])\n",
    "    features_df['full_feature_set'] = features_df.full_feature_lst.apply(set)\n",
    "    \n",
    "    df_full = df_full.merge(features_df, on='dataset')\n",
    "#     print(df_full.columns)\n",
    "    dropped_feature_set = get_feature_sets(df_full)\n",
    "#     print(dropped_feature_set)\n",
    "    df_full = df_full.join(dropped_feature_set)\n",
    "    \n",
    "    df_full['current_feature_set'] = (df_full['full_feature_set'] - df_full['dropped_feature_set'])\n",
    "    df_full['current_feature_str'] = (df_full['full_feature_set'] - df_full['dropped_feature_set'])\n",
    "    \n",
    "    df_full['current_feature_str'] = df_full.current_feature_set.apply(str)\n",
    "#     print(df_full.columns)\n",
    "    \n",
    "#     trash\n",
    "#     df_full['features_dropped_lst'] = [y.dropped_feature.tolist()[:z+1] for x, y in df_full.groupby(['model','imp_type', 'dataset','random_state', 'data_split']) for z in range(len(y))]\n",
    "#     df_full['features_dropped_set'] = df_full['features_dropped_lst'].apply(set)\n",
    "#     original_shape, df_full.shape\n",
    "#     df_full['feature_set'] =  df_full['full_feature_set'] - df_full['features_dropped_set']\n",
    "    return df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regr_features(df):\n",
    "    cols = ['dataset', 'random_state', 'data_split', 'model', 'imp_type', 'mse_test']\n",
    "    idx = ['dataset', 'random_state', 'data_split', 'model', 'imp_type']\n",
    "\n",
    "    init_metric = df.query('dropped_feature == \"full_set\"')\n",
    "    init_metric = init_metric.groupby(idx).mse_test.max()\n",
    "    init_metric = init_metric.rename('init_mse_test')\n",
    "\n",
    "    # merge into original df\n",
    "    df_full= pd.merge(df, init_metric, on=idx, how='inner')\n",
    "    \n",
    "    cols = ['dataset', 'iteration']\n",
    "    idx = ['dataset']\n",
    "    max_feature_cnt = df[cols]\n",
    "    max_feature_cnt = max_feature_cnt.groupby(idx).max() + 1\n",
    "\n",
    "    max_feature_cnt['f_cnt_10perc'] = np.round((max_feature_cnt.iteration * 0.1)).astype(int)\n",
    "    max_feature_cnt['f_cnt_20perc'] = np.round((max_feature_cnt.iteration * 0.2)).astype(int)\n",
    "    max_feature_cnt['f_cnt_30perc'] = np.round((max_feature_cnt.iteration * 0.3)).astype(int)\n",
    "    max_feature_cnt = max_feature_cnt.rename(columns={'iteration':'max_feature_cnt'})\n",
    "\n",
    "    # merge into original df\n",
    "    df_full = pd.merge(df_full, max_feature_cnt, on=idx, how='inner')\n",
    "    \n",
    "    df_full['mse_delta'] = df_full.init_mse_test - df_full.mse_test\n",
    "    df_full['mse_perc'] = df_full.mse_delta / df_full.init_mse_test\n",
    "    df_full['feature_cnt'] = df_full.max_feature_cnt - df_full.iteration\n",
    "    df_full['pp_coef'] = df_full.init_mse_test / df_full.mse_test\n",
    "    # df_full['pp_coef'] = df_full.init_mse_test / df_full.mse_test\n",
    "\n",
    "    # max_perc grouping\n",
    "    grouping = ['dataset', 'random_state', 'data_split', 'model', 'imp_type']\n",
    "\n",
    "    # select all non-base models\n",
    "    max_perc = df_full.query('iteration > 0')\n",
    "    max_perc = max_perc.groupby(grouping).mse_perc.max()\n",
    "    max_perc = max_perc.rename('max_perc')\n",
    "\n",
    "    df_full = pd.merge(df_full, max_perc, on=grouping, how='inner')\n",
    "    \n",
    "    df_full['feature_dropped'] =  df_full.max_feature_cnt - df_full.feature_cnt\n",
    "    df_full['feature_dropped_perc'] = (1 - (df_full.max_feature_cnt - df_full.feature_dropped) \n",
    "                                   / df_full.max_feature_cnt)\n",
    "    \n",
    "    features_df = pd.DataFrame(datasets.items(), columns=['dataset', 'full_feature_lst'])\n",
    "    features_df['full_feature_set'] = features_df.full_feature_lst.apply(set)\n",
    "    \n",
    "    df_full = df_full.merge(features_df, on='dataset')\n",
    "#     print(df_full.columns)\n",
    "    dropped_feature_set = get_feature_sets(df_full)\n",
    "#     print(dropped_feature_set)\n",
    "    df_full = df_full.join(dropped_feature_set)\n",
    "    \n",
    "    df_full['current_feature_set'] = (df_full['full_feature_set'] - df_full['dropped_feature_set'])\n",
    "    df_full['current_feature_str'] = (df_full['full_feature_set'] - df_full['dropped_feature_set'])\n",
    "    \n",
    "    df_full['current_feature_str'] = df_full.current_feature_set.apply(str)\n",
    "#     print(df_full.columns)\n",
    "    \n",
    "#     trash\n",
    "#     df_full['features_dropped_lst'] = [y.dropped_feature.tolist()[:z+1] for x, y in df_full.groupby(['model','imp_type', 'dataset','random_state', 'data_split']) for z in range(len(y))]\n",
    "#     df_full['features_dropped_set'] = df_full['features_dropped_lst'].apply(set)\n",
    "#     original_shape, df_full.shape\n",
    "#     df_full['feature_set'] =  df_full['full_feature_set'] - df_full['features_dropped_set']\n",
    "    return df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_sets(df):\n",
    "    # this is really bad performance wise, but since \n",
    "    # we need inter-record actions we have no choice\n",
    "    # there is proubably a way to optimize this since we process small subarrays\n",
    "    lst = []\n",
    "    start = 0\n",
    "    for i in range(len(df)):\n",
    "        curr_arr = df.iloc[i]\n",
    "        # at the start of a new experiment move dataset start pointer\n",
    "        if curr_arr.iteration == 0:\n",
    "            start = i\n",
    "        sub_arr = df.iloc[start:i+1]\n",
    "        # grab all dropped features\n",
    "        all_dropped = set(sub_arr.dropped_feature.tolist())\n",
    "        all_dropped.remove('full_set')\n",
    "        \n",
    "        # old stuff\n",
    "        # set_dataset = curr_arr.full_feature_set\n",
    "        # select feature intersection\n",
    "        # set_features = set_all & set_dataset\n",
    "\n",
    "        lst.append(all_dropped)\n",
    "        \n",
    "    feature_arr = pd.Series(lst, name='dropped_feature_set')   \n",
    "    return feature_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def case3_regr(df):\n",
    "    # minimal model only use 80% of features in all cases\n",
    "    case3 = df[df.f_cnt_20perc == df.feature_cnt]\n",
    "\n",
    "    relevant_columns = ['dataset', 'current_feature_str', \n",
    "                        'mse_test', 'init_mse_test','model']\n",
    "    case3 = case3[relevant_columns]\n",
    "\n",
    "    init_mcc = case3.groupby(['dataset','model'], sort=False).mean()\n",
    "    init_mcc = init_mcc.init_mse_test.rename('init_mse_test_mean')\n",
    "\n",
    "    case3 = case3.join(init_mcc, on=['dataset', 'model'])\n",
    "\n",
    "    case3 = case3.groupby(['dataset','model','current_feature_str'], sort=False).mean()\n",
    "\n",
    "#     case3 = case3.groupby(['dataset','model','current_feature_str'], sort=False).mean()\n",
    "\n",
    "    case3 = case3[['mse_test', 'init_mse_test_mean']].sort_values(['dataset', 'model', 'mse_test'], ascending=False)\n",
    "    case3.reset_index();\n",
    "\n",
    "    min_mse = case3.groupby(['dataset', 'model']).min().mse_test.rename('min_mse')\n",
    "\n",
    "    case3 = case3.join(min_mse, on=['dataset', 'model'])\n",
    "\n",
    "    case3 = case3.query('mse_test == min_mse')\n",
    "\n",
    "    case3.drop_duplicates();\n",
    "    \n",
    "    case3['mse_gain_loss_pct'] = round((((case3['init_mse_test_mean'] / case3['mse_test']) - 1) * 100),2)\n",
    "\n",
    "    case3.drop(['min_mse'], inplace=True, axis=1)\n",
    "    \n",
    "    return case3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def case2_regr(df):\n",
    "    # case2 main condition: no accuracy lost\n",
    "    max_dropped = df.query('mse_test <= init_mse_test')\n",
    "\n",
    "    relevant_columns = ['data_split','random_state', 'dataset', 'imp_type', \n",
    "                        'current_feature_str', 'feature_dropped_perc', 'model', 'mse_test', 'init_mse_test']\n",
    "    test = max_dropped[relevant_columns]\n",
    "\n",
    "    # get features sets that maximize feature dropped perc\n",
    "    idx = test.groupby(['dataset', 'model','data_split', 'random_state'], sort=False)['feature_dropped_perc'].idxmax()\n",
    "\n",
    "    test2 = test.loc[idx].sort_values('feature_dropped_perc', ascending=False)\n",
    "    \n",
    "    init_mse = test2.groupby(['dataset','model'], sort=False).mean()\n",
    "    init_mse = init_mse.init_mse_test.rename('init_mse_test_mean')\n",
    "\n",
    "    test2 = test2.join(init_mse, on=['dataset', 'model'])\n",
    "    \n",
    "    max_feature_dropped = test2.groupby(['dataset', 'model']).feature_dropped_perc.max()\n",
    "    max_feature_dropped.rename('max_feature_dropped', inplace=True);\n",
    "\n",
    "    test3 = test2.merge(max_feature_dropped, on=['dataset', 'model'])\n",
    "\n",
    "    test4 = test3.query('feature_dropped_perc == max_feature_dropped')\n",
    "\n",
    "    grouping = ['dataset', 'model', 'current_feature_str', 'feature_dropped_perc', 'mse_test','init_mse_test_mean']\n",
    "    final_df = test4[grouping].groupby(['dataset', 'model', 'current_feature_str']).mean()\n",
    "    final_df = final_df.drop_duplicates().sort_values(['dataset','model'], ascending=False)\n",
    "    \n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def case1_regr(df):  \n",
    "    grouping = ['model','iteration','mse_test','init_mse_test', 'current_feature_str','imp_type','max_perc','random_state', 'data_split', 'dataset', 'current_feature_set']\n",
    "    case1 = df[grouping]\n",
    "    # case1 = case1[case1.mcc_perc == case1.max_perc]\n",
    "    case1['current_feature_cnt'] = case1['current_feature_set'].apply(len)\n",
    "\n",
    "    # avg coalition mse\n",
    "    mse_coalition = case1.groupby(['dataset', 'model', 'current_feature_str']).mean()\n",
    "\n",
    "    mse_coalition = mse_coalition[['mse_test', 'init_mse_test', 'current_feature_cnt']]\n",
    "\n",
    "    mse_coalition = mse_coalition.sort_values(['dataset', 'model', 'mse_test'], ascending=False)\n",
    "\n",
    "    max_mse_coal = mse_coalition.groupby(['dataset', 'model']).min().mse_test\n",
    "    max_mse_coal.rename('max_coal_mse', inplace=True);\n",
    "\n",
    "    mse_coalition = mse_coalition.join(max_mse_coal)\n",
    "\n",
    "    mse_coalition = mse_coalition.query('mse_test == max_coal_mse')\n",
    "\n",
    "    min_f = mse_coalition.groupby(['dataset', 'model']).min().current_feature_cnt; min_f.rename('min_feat_cnt', inplace=True);\n",
    "\n",
    "    mse_coalition = mse_coalition.join(min_f)\n",
    "\n",
    "    mse_coalition = mse_coalition.query('current_feature_cnt == min_feat_cnt')\n",
    "\n",
    "    mse_coalition['mse_gain_loss_pct'] = round((mse_coalition['init_mse_test'] / mse_coalition['mse_test'] - 1) * 100, 2)\n",
    "\n",
    "    case1 = mse_coalition.sort_values(['dataset', 'model','mse_test'], ascending=False)[['mse_test', 'init_mse_test','mse_gain_loss_pct']]\n",
    "    \n",
    "    return case1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parity_analysis_regr(df_case1):\n",
    "    \n",
    "    res1 = df_case1.reset_index()\n",
    "    \n",
    "    res1 = res1.pivot(index='dataset', columns='model', values=['init_mse_test', 'mse_test']).sort_values('dataset', ascending=False)\n",
    "\n",
    "    res1.columns = res1.columns.to_flat_index()\n",
    "\n",
    "    res1\n",
    "\n",
    "    columns = ['DT(all)', 'RF(all)', 'GBDT(all)', 'DT(opt)', 'RF(opt)','GBDT(opt)']\n",
    "\n",
    "    res1.columns = columns; res1\n",
    "\n",
    "    res1 = res1[['DT(opt)', 'DT(all)', 'RF(all)', 'RF(opt)', 'GBDT(all)', 'GBDT(opt)']]\n",
    "\n",
    "    res1\n",
    "\n",
    "    pct_diff = res1.copy()\n",
    "    res1['task'] = 'regression'\n",
    "    res1['metric'] = 'mse'\n",
    "    \n",
    "    # compare simple vs complex\n",
    "    pct_diff['DT(all)vsRF(all)'] = pct_diff['RF(all)'] / pct_diff['DT(all)']\n",
    "    pct_diff['DT(all)vsGBDT(all)'] = pct_diff['GBDT(all)'] / pct_diff['DT(all)'] \n",
    "\n",
    "    # simple opt vs complex unopt\n",
    "    pct_diff['DT(opt)vsRF(all)'] = pct_diff['RF(all)'] / pct_diff['DT(opt)'] \n",
    "    pct_diff['DT(opt)vsGBDT(all)'] =  pct_diff['GBDT(all)'] / pct_diff['DT(opt)']\n",
    "    \n",
    "    # reduce complex model complexity\n",
    "    pct_diff['RF(opt)vsRF(all)'] =  pct_diff['RF(all)'] / pct_diff['RF(opt)']\n",
    "    pct_diff['GBDT(opt)vsGBDT(all)'] = pct_diff['GBDT(all)'] / pct_diff['GBDT(opt)']\n",
    "    \n",
    "#     # simple models {opt, all} vs complex optimized\n",
    "#     # simple all\n",
    "#     pct_diff['DT(all)vsRF(opt)'] = pct_diff['RF(opt)'] / pct_diff['DT(all)']\n",
    "#     pct_diff['DT(all)vsGBDT(opt)'] = pct_diff['GBDT(opt)'] / pct_diff['DT(all)']\n",
    "#     # simple opt\n",
    "#     pct_diff['DT(opt)vsRF(opt)'] = pct_diff['DT(opt)'] / pct_diff['RF(opt)']\n",
    "#     pct_diff['DT(opt)vsGBDT(opt)'] = pct_diff['DT(opt)'] / pct_diff['GBDT(opt)']\n",
    "\n",
    "    pct_diff = round(pct_diff[['DT(all)vsRF(all)','DT(opt)vsRF(all)',\n",
    "                               'DT(all)vsGBDT(all)', 'DT(opt)vsGBDT(all)',\n",
    "                               'RF(opt)vsRF(all)', 'GBDT(opt)vsGBDT(all)',\n",
    "                              ]\n",
    "                             ] * 100, 2)\n",
    "    pct_diff['task'] = 'regression'\n",
    "    pct_diff['metric'] = 'mse'\n",
    "    \n",
    "    return pct_diff, res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parity_regr, parity_regr_all = parity_analysis_regr(res1_regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "def case3_clasif(df):\n",
    "    # minimal model only use 80% of features in all cases\n",
    "    case3 = df[df.f_cnt_20perc == df.feature_cnt]\n",
    "\n",
    "    relevant_columns = ['dataset', 'current_feature_str', \n",
    "                        'mcc_test', 'init_mcc_test','model']\n",
    "    case3 = case3[relevant_columns]\n",
    "\n",
    "    init_mcc = case3.groupby(['dataset','model'], sort=False).mean()\n",
    "    init_mcc = init_mcc.init_mcc_test.rename('init_mcc_test_mean')\n",
    "\n",
    "    case3 = case3.join(init_mcc, on=['dataset', 'model'])\n",
    "\n",
    "    case3 = case3.groupby(['dataset','model','current_feature_str'], sort=False).mean()\n",
    "\n",
    "    case3 = case3.groupby(['dataset','model','current_feature_str'], sort=False).mean()\n",
    "\n",
    "    case3 = case3[['mcc_test', 'init_mcc_test_mean']].sort_values(['dataset', 'model', 'mcc_test'], ascending=False)\n",
    "    case3.reset_index();\n",
    "\n",
    "    max_mcc = case3.groupby(['dataset', 'model']).max().mcc_test.rename('max_mcc')\n",
    "\n",
    "    case3 = case3.join(max_mcc, on=['dataset', 'model'])\n",
    "\n",
    "    case3 = case3.query('mcc_test == max_mcc')\n",
    "\n",
    "    case3.drop_duplicates();\n",
    "\n",
    "    case3['mcc_gain_loss'] = round((case3['mcc_test'] / case3['init_mcc_test_mean'] - 1) * 100, 2)\n",
    "\n",
    "    case3.drop(['max_mcc'], inplace=True, axis=1)\n",
    "    \n",
    "    return case3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "def case2_clasif(df):\n",
    "    # case2 main condition: no accuracy lost\n",
    "    max_dropped = df.query('mcc_test  >= init_mcc_test')\n",
    "\n",
    "    relevant_columns = ['data_split','random_state', 'dataset', 'imp_type', \n",
    "                        'current_feature_str', 'feature_dropped_perc', 'model', 'mcc_test', 'init_mcc_test']\n",
    "    test = max_dropped[relevant_columns]\n",
    "\n",
    "    # get features sets that maximize feature dropped perc\n",
    "    idx = test.groupby(['dataset', 'model','data_split', 'random_state'], sort=False)['feature_dropped_perc'].idxmax()\n",
    "\n",
    "    test2 = test.loc[idx].sort_values('feature_dropped_perc', ascending=False)\n",
    "    \n",
    "    init_mcc = test2.groupby(['dataset','model'], sort=False).mean()\n",
    "    init_mcc = init_mcc.init_mcc_test.rename('init_mcc_test_mean')\n",
    "\n",
    "    test2 = test2.join(init_mcc, on=['dataset', 'model'])\n",
    "\n",
    "    max_feature_dropped = test2.groupby(['dataset', 'model']).feature_dropped_perc.max()\n",
    "    max_feature_dropped.rename('max_feature_dropped', inplace=True);\n",
    "\n",
    "    test3 = test2.merge(max_feature_dropped, on=['dataset', 'model'])\n",
    "\n",
    "    test4 = test3.query('feature_dropped_perc == max_feature_dropped')\n",
    "\n",
    "    grouping = ['dataset', 'model', 'current_feature_str', 'feature_dropped_perc', 'mcc_test','init_mcc_test_mean']\n",
    "    final_df = test4[grouping].groupby(['dataset', 'model', 'current_feature_str']).mean()\n",
    "    final_df = final_df.drop_duplicates().sort_values(['dataset','model'], ascending=False)\n",
    "    \n",
    "    \n",
    "    return final_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "def case1_clasif(df):  \n",
    "    grouping = ['model','iteration','mcc_test', 'mcc_perc','init_mcc_test', 'current_feature_str','imp_type','max_perc','random_state', 'data_split', 'dataset', 'current_feature_set']\n",
    "    case1 = df[grouping]\n",
    "    # case1 = case1[case1.mcc_perc == case1.max_perc]\n",
    "    case1['current_feature_cnt'] = case1['current_feature_set'].apply(len)\n",
    "\n",
    "    # avg coalition mcc\n",
    "    mcc_coalition = case1.groupby(['dataset', 'model', 'current_feature_str']).mean()\n",
    "\n",
    "    mcc_coalition = mcc_coalition[['mcc_test', 'init_mcc_test', 'current_feature_cnt']]\n",
    "\n",
    "    mcc_coalition = mcc_coalition.sort_values(['dataset', 'model', 'mcc_test'], ascending=False)\n",
    "\n",
    "    max_mcc_coal = mcc_coalition.groupby(['dataset', 'model']).max().mcc_test\n",
    "    max_mcc_coal.rename('max_coal_mcc', inplace=True);\n",
    "\n",
    "    mcc_coalition = mcc_coalition.join(max_mcc_coal)\n",
    "\n",
    "    mcc_coalition = mcc_coalition.query('mcc_test == max_coal_mcc')\n",
    "\n",
    "    min_f = mcc_coalition.groupby(['dataset', 'model']).min().current_feature_cnt; min_f.rename('min_feat_cnt', inplace=True);\n",
    "\n",
    "    mcc_coalition = mcc_coalition.join(min_f)\n",
    "\n",
    "    mcc_coalition = mcc_coalition.query('current_feature_cnt == min_feat_cnt')\n",
    "\n",
    "    mcc_coalition['mcc_gain_loss'] = round((mcc_coalition['mcc_test'] / mcc_coalition['init_mcc_test'] - 1) * 100, 2)\n",
    "\n",
    "    case1 = mcc_coalition.sort_values(['dataset', 'model','mcc_test'], ascending=False)[['mcc_test', 'init_mcc_test','mcc_gain_loss']]\n",
    "    \n",
    "    return case1\n",
    "\n",
    "def parity_analysis_clasif(df_case1):\n",
    "    \n",
    "    res1 = df_case1\n",
    "    res1 = res1.reset_index()\n",
    "    res1 = res1[['dataset', 'model', 'mcc_test','init_mcc_test']]\n",
    "#     res1 = res1.drop_duplicates()\n",
    "    \n",
    "    res1 = (res1\n",
    "#             .reset_index()\n",
    "            .groupby(['dataset','model'])\n",
    "            .first()\n",
    "            .reset_index()\n",
    "            .sort_values(['dataset', 'model', 'mcc_test'], ascending=False))\n",
    "    \n",
    "#     print(res1.sort_values('dataset', ascending=False).head(20))\n",
    "    \n",
    "    res1 = res1.pivot(index='dataset', columns='model', values=['init_mcc_test', 'mcc_test']).sort_values('dataset', ascending=False)\n",
    "\n",
    "    res1.columns = res1.columns.to_flat_index()\n",
    "\n",
    "    res1\n",
    "\n",
    "    columns = ['DT(all)', 'RF(all)', 'GBDT(all)', 'DT(opt)', 'RF(opt)','GBDT(opt)']\n",
    "\n",
    "    res1.columns = columns; res1\n",
    "\n",
    "    res1 = res1[['DT(opt)', 'DT(all)', 'RF(all)', 'RF(opt)', 'GBDT(all)', 'GBDT(opt)']]\n",
    "\n",
    "#     print(res1.index)\n",
    "\n",
    "    pct_diff = res1.copy()\n",
    "    res1['task'] = 'classification'\n",
    "    res1['metric'] = 'mcc'\n",
    "    \n",
    "    # compare simple vs complex\n",
    "    pct_diff['DT(all)vsRF(all)'] = pct_diff['DT(all)'] / pct_diff['RF(all)']\n",
    "    pct_diff['DT(all)vsGBDT(all)'] = pct_diff['DT(all)'] / pct_diff['GBDT(all)']\n",
    "    \n",
    "    # simple models vs complex unoptimized\n",
    "    pct_diff['DT(opt)vsRF(all)'] = pct_diff['DT(opt)'] / pct_diff['RF(all)']\n",
    "    pct_diff['DT(opt)vsGBDT(all)'] = pct_diff['DT(opt)'] / pct_diff['GBDT(all)']\n",
    "    \n",
    "    # reduce complex model complexity\n",
    "    pct_diff['RF(opt)vsRF(all)'] = pct_diff['RF(opt)'] / pct_diff['RF(all)']\n",
    "    pct_diff['GBDT(opt)vsGBDT(all)'] = pct_diff['GBDT(opt)'] / pct_diff['GBDT(all)']\n",
    "\n",
    "#     # simple models vs complex unoptimized\n",
    "#     pct_diff['DT(opt)vsRF(all)'] = pct_diff['DT(opt)'] / pct_diff['RF(all)']\n",
    "#     pct_diff['DT(opt)vsGBDT(all)'] = pct_diff['DT(opt)'] / pct_diff['GBDT(all)']\n",
    "    \n",
    "#     # simple models {opt, all} vs complex optimized\n",
    "#     # simple all\n",
    "#     pct_diff['DT(all)vsRF(opt)'] = pct_diff['DT(all)'] / pct_diff['RF(opt)']\n",
    "#     pct_diff['DT(all)vsGBDT(opt)'] = pct_diff['DT(all)'] / pct_diff['GBDT(opt)'] \n",
    "#     # simple opt\n",
    "#     pct_diff['DT(opt)vsRF(opt)'] = pct_diff['DT(opt)'] / pct_diff['RF(opt)']\n",
    "#     pct_diff['DT(opt)vsGBDT(opt)'] = pct_diff['DT(opt)'] / pct_diff['GBDT(opt)'] \n",
    "\n",
    "    pct_diff = round(pct_diff[['DT(all)vsRF(all)','DT(opt)vsRF(all)',\n",
    "                               'DT(all)vsGBDT(all)', 'DT(opt)vsGBDT(all)',\n",
    "                               'RF(opt)vsRF(all)', 'GBDT(opt)vsGBDT(all)',\n",
    "                              ]\n",
    "                             ] * 100, 2)\n",
    "    pct_diff['task'] = 'classification'\n",
    "    pct_diff['metric'] = 'mcc'\n",
    "    \n",
    "    return pct_diff, res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parity_clasif, parity_clasif_all = parity_analysis_clasif(res1_clasif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res1_clasif;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res1_clasif.reset_index().groupby(['dataset','model']).first().sort_values(['dataset', 'model', 'mcc_test'], ascending=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_clasif = lst_dfs[0]\n",
    "# df_clasif = get_clasif_features(df.iloc[:10000])\n",
    "# df_clasif = get_clasif_features(df_clasif)\n",
    "\n",
    "# res2_clasif = case2_clasif(df_clasif)\n",
    "\n",
    "# res3_clasif = case3_clasif(df_clasif)\n",
    "\n",
    "# res1_clasif = case1_clasif(df_clasif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df_regr = lst_dfs[1]\n",
    "# # df_regr = get_regr_features(df_regr.iloc[:10000])\n",
    "# # df_regr = get_regr_features(df_regr)\n",
    "\n",
    "# res3_regr = case3_regr(df_regr); res3_regr;\n",
    "\n",
    "# res2_regr = case2_regr(df_regr); res2_regr;\n",
    "\n",
    "# res1_regr = case1_regr(df_regr); res1_regr;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump data to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res1_clasif.to_csv('results_coalition_parity/case1_coalition_clasif.csv')\n",
    "\n",
    "# res2_clasif.to_csv('results_coalition_parity/case2_coalition_clasif.csv')\n",
    "\n",
    "# res3_clasif.to_csv('results_coalition_parity/case3_coalition_clasif.csv')\n",
    "\n",
    "# res1_regr.to_csv('results_coalition_parity/case1_coalition_regr.csv')\n",
    "\n",
    "# res2_regr.to_csv('results_coalition_parity/case2_coalition_regr.csv')\n",
    "\n",
    "# res3_regr.to_csv('results_coalition_parity/case3_coalition_regr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "parity_regr, parity_regr_all = parity_analysis_regr(res1_regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "parity_clasif, parity_clasif_all = parity_analysis_clasif(res1_clasif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "parity_small = pd.concat([parity_regr, parity_clasif])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "parity_large = pd.concat([parity_regr_all, parity_clasif_all])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DT(opt)</th>\n",
       "      <th>DT(all)</th>\n",
       "      <th>RF(all)</th>\n",
       "      <th>RF(opt)</th>\n",
       "      <th>GBDT(all)</th>\n",
       "      <th>GBDT(opt)</th>\n",
       "      <th>task</th>\n",
       "      <th>metric</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>diabetes</th>\n",
       "      <td>4.574541e+03</td>\n",
       "      <td>6.214880e+03</td>\n",
       "      <td>2.904814e+03</td>\n",
       "      <td>2.734083e+03</td>\n",
       "      <td>3.082448e+03</td>\n",
       "      <td>3.352718e+03</td>\n",
       "      <td>regression</td>\n",
       "      <td>mse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crime</th>\n",
       "      <td>2.585679e-02</td>\n",
       "      <td>3.909593e-02</td>\n",
       "      <td>1.730625e-02</td>\n",
       "      <td>1.618907e-02</td>\n",
       "      <td>1.890048e-02</td>\n",
       "      <td>1.620825e-02</td>\n",
       "      <td>regression</td>\n",
       "      <td>mse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boston</th>\n",
       "      <td>1.614947e+01</td>\n",
       "      <td>1.737671e+01</td>\n",
       "      <td>9.071403e+00</td>\n",
       "      <td>1.074200e+01</td>\n",
       "      <td>1.119797e+01</td>\n",
       "      <td>1.029483e+01</td>\n",
       "      <td>regression</td>\n",
       "      <td>mse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ames_housing</th>\n",
       "      <td>9.494084e+08</td>\n",
       "      <td>1.264754e+09</td>\n",
       "      <td>5.421401e+08</td>\n",
       "      <td>5.251412e+08</td>\n",
       "      <td>4.773048e+08</td>\n",
       "      <td>4.318682e+08</td>\n",
       "      <td>regression</td>\n",
       "      <td>mse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wine</th>\n",
       "      <td>9.725563e-01</td>\n",
       "      <td>9.725563e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>classification</td>\n",
       "      <td>mcc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phishing</th>\n",
       "      <td>9.347885e-01</td>\n",
       "      <td>9.299563e-01</td>\n",
       "      <td>9.468502e-01</td>\n",
       "      <td>9.517603e-01</td>\n",
       "      <td>9.419477e-01</td>\n",
       "      <td>9.474607e-01</td>\n",
       "      <td>classification</td>\n",
       "      <td>mcc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mushroom</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>classification</td>\n",
       "      <td>mcc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breast_cancer</th>\n",
       "      <td>9.625013e-01</td>\n",
       "      <td>8.871975e-01</td>\n",
       "      <td>9.506628e-01</td>\n",
       "      <td>9.754854e-01</td>\n",
       "      <td>9.754854e-01</td>\n",
       "      <td>9.754854e-01</td>\n",
       "      <td>classification</td>\n",
       "      <td>mcc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    DT(opt)       DT(all)       RF(all)       RF(opt)  \\\n",
       "dataset                                                                 \n",
       "diabetes       4.574541e+03  6.214880e+03  2.904814e+03  2.734083e+03   \n",
       "crime          2.585679e-02  3.909593e-02  1.730625e-02  1.618907e-02   \n",
       "boston         1.614947e+01  1.737671e+01  9.071403e+00  1.074200e+01   \n",
       "ames_housing   9.494084e+08  1.264754e+09  5.421401e+08  5.251412e+08   \n",
       "wine           9.725563e-01  9.725563e-01  1.000000e+00  1.000000e+00   \n",
       "phishing       9.347885e-01  9.299563e-01  9.468502e-01  9.517603e-01   \n",
       "mushroom       1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "breast_cancer  9.625013e-01  8.871975e-01  9.506628e-01  9.754854e-01   \n",
       "\n",
       "                  GBDT(all)     GBDT(opt)            task metric  \n",
       "dataset                                                           \n",
       "diabetes       3.082448e+03  3.352718e+03      regression    mse  \n",
       "crime          1.890048e-02  1.620825e-02      regression    mse  \n",
       "boston         1.119797e+01  1.029483e+01      regression    mse  \n",
       "ames_housing   4.773048e+08  4.318682e+08      regression    mse  \n",
       "wine           1.000000e+00  1.000000e+00  classification    mcc  \n",
       "phishing       9.419477e-01  9.474607e-01  classification    mcc  \n",
       "mushroom       1.000000e+00  1.000000e+00  classification    mcc  \n",
       "breast_cancer  9.754854e-01  9.754854e-01  classification    mcc  "
      ]
     },
     "execution_count": 657,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parity_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DT(opt)</th>\n",
       "      <th>DT(all)</th>\n",
       "      <th>RF(all)</th>\n",
       "      <th>RF(opt)</th>\n",
       "      <th>GBDT(all)</th>\n",
       "      <th>GBDT(opt)</th>\n",
       "      <th>task</th>\n",
       "      <th>metric</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>diabetes</th>\n",
       "      <td>4.574541e+03</td>\n",
       "      <td>6.214880e+03</td>\n",
       "      <td>2.904814e+03</td>\n",
       "      <td>2.734083e+03</td>\n",
       "      <td>3.082448e+03</td>\n",
       "      <td>3.352718e+03</td>\n",
       "      <td>regression</td>\n",
       "      <td>mse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crime</th>\n",
       "      <td>2.585679e-02</td>\n",
       "      <td>3.909593e-02</td>\n",
       "      <td>1.730625e-02</td>\n",
       "      <td>1.618907e-02</td>\n",
       "      <td>1.890048e-02</td>\n",
       "      <td>1.620825e-02</td>\n",
       "      <td>regression</td>\n",
       "      <td>mse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boston</th>\n",
       "      <td>1.614947e+01</td>\n",
       "      <td>1.737671e+01</td>\n",
       "      <td>9.071403e+00</td>\n",
       "      <td>1.074200e+01</td>\n",
       "      <td>1.119797e+01</td>\n",
       "      <td>1.029483e+01</td>\n",
       "      <td>regression</td>\n",
       "      <td>mse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ames_housing</th>\n",
       "      <td>9.494084e+08</td>\n",
       "      <td>1.264754e+09</td>\n",
       "      <td>5.421401e+08</td>\n",
       "      <td>5.251412e+08</td>\n",
       "      <td>4.773048e+08</td>\n",
       "      <td>4.318682e+08</td>\n",
       "      <td>regression</td>\n",
       "      <td>mse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wine</th>\n",
       "      <td>9.725563e-01</td>\n",
       "      <td>9.725563e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>classification</td>\n",
       "      <td>mcc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phishing</th>\n",
       "      <td>9.347885e-01</td>\n",
       "      <td>9.299563e-01</td>\n",
       "      <td>9.468502e-01</td>\n",
       "      <td>9.517603e-01</td>\n",
       "      <td>9.419477e-01</td>\n",
       "      <td>9.474607e-01</td>\n",
       "      <td>classification</td>\n",
       "      <td>mcc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mushroom</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>classification</td>\n",
       "      <td>mcc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breast_cancer</th>\n",
       "      <td>9.625013e-01</td>\n",
       "      <td>8.871975e-01</td>\n",
       "      <td>9.506628e-01</td>\n",
       "      <td>9.754854e-01</td>\n",
       "      <td>9.754854e-01</td>\n",
       "      <td>9.754854e-01</td>\n",
       "      <td>classification</td>\n",
       "      <td>mcc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    DT(opt)       DT(all)       RF(all)       RF(opt)  \\\n",
       "dataset                                                                 \n",
       "diabetes       4.574541e+03  6.214880e+03  2.904814e+03  2.734083e+03   \n",
       "crime          2.585679e-02  3.909593e-02  1.730625e-02  1.618907e-02   \n",
       "boston         1.614947e+01  1.737671e+01  9.071403e+00  1.074200e+01   \n",
       "ames_housing   9.494084e+08  1.264754e+09  5.421401e+08  5.251412e+08   \n",
       "wine           9.725563e-01  9.725563e-01  1.000000e+00  1.000000e+00   \n",
       "phishing       9.347885e-01  9.299563e-01  9.468502e-01  9.517603e-01   \n",
       "mushroom       1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "breast_cancer  9.625013e-01  8.871975e-01  9.506628e-01  9.754854e-01   \n",
       "\n",
       "                  GBDT(all)     GBDT(opt)            task metric  \n",
       "dataset                                                           \n",
       "diabetes       3.082448e+03  3.352718e+03      regression    mse  \n",
       "crime          1.890048e-02  1.620825e-02      regression    mse  \n",
       "boston         1.119797e+01  1.029483e+01      regression    mse  \n",
       "ames_housing   4.773048e+08  4.318682e+08      regression    mse  \n",
       "wine           1.000000e+00  1.000000e+00  classification    mcc  \n",
       "phishing       9.419477e-01  9.474607e-01  classification    mcc  \n",
       "mushroom       1.000000e+00  1.000000e+00  classification    mcc  \n",
       "breast_cancer  9.754854e-01  9.754854e-01  classification    mcc  "
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parity_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouping_simple_models = ['DT(all)vsRF(all)','DT(opt)vsRF(all)',\n",
    "            'DT(all)vsGBDT(all)', 'DT(opt)vsGBDT(all)', 'task' ,'metric'\n",
    "                              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouping_complex_models = ['RF(opt)vsRF(all)', 'GBDT(opt)vsGBDT(all)', 'task', 'metric']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DT(all)vsRF(all)</th>\n",
       "      <th>DT(opt)vsRF(all)</th>\n",
       "      <th>DT(all)vsGBDT(all)</th>\n",
       "      <th>DT(opt)vsGBDT(all)</th>\n",
       "      <th>task</th>\n",
       "      <th>metric</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>diabetes</th>\n",
       "      <td>46.74</td>\n",
       "      <td>63.50</td>\n",
       "      <td>49.60</td>\n",
       "      <td>67.38</td>\n",
       "      <td>regression</td>\n",
       "      <td>mse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crime</th>\n",
       "      <td>44.27</td>\n",
       "      <td>66.93</td>\n",
       "      <td>48.34</td>\n",
       "      <td>73.10</td>\n",
       "      <td>regression</td>\n",
       "      <td>mse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boston</th>\n",
       "      <td>52.20</td>\n",
       "      <td>56.17</td>\n",
       "      <td>64.44</td>\n",
       "      <td>69.34</td>\n",
       "      <td>regression</td>\n",
       "      <td>mse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ames_housing</th>\n",
       "      <td>42.87</td>\n",
       "      <td>57.10</td>\n",
       "      <td>37.74</td>\n",
       "      <td>50.27</td>\n",
       "      <td>regression</td>\n",
       "      <td>mse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wine</th>\n",
       "      <td>97.26</td>\n",
       "      <td>97.26</td>\n",
       "      <td>97.26</td>\n",
       "      <td>97.26</td>\n",
       "      <td>classification</td>\n",
       "      <td>mcc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phishing</th>\n",
       "      <td>98.22</td>\n",
       "      <td>98.73</td>\n",
       "      <td>98.73</td>\n",
       "      <td>99.24</td>\n",
       "      <td>classification</td>\n",
       "      <td>mcc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mushroom</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>classification</td>\n",
       "      <td>mcc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breast_cancer</th>\n",
       "      <td>93.32</td>\n",
       "      <td>101.25</td>\n",
       "      <td>90.95</td>\n",
       "      <td>98.67</td>\n",
       "      <td>classification</td>\n",
       "      <td>mcc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               DT(all)vsRF(all)  DT(opt)vsRF(all)  DT(all)vsGBDT(all)  \\\n",
       "dataset                                                                 \n",
       "diabetes                  46.74             63.50               49.60   \n",
       "crime                     44.27             66.93               48.34   \n",
       "boston                    52.20             56.17               64.44   \n",
       "ames_housing              42.87             57.10               37.74   \n",
       "wine                      97.26             97.26               97.26   \n",
       "phishing                  98.22             98.73               98.73   \n",
       "mushroom                 100.00            100.00              100.00   \n",
       "breast_cancer             93.32            101.25               90.95   \n",
       "\n",
       "               DT(opt)vsGBDT(all)            task metric  \n",
       "dataset                                                   \n",
       "diabetes                    67.38      regression    mse  \n",
       "crime                       73.10      regression    mse  \n",
       "boston                      69.34      regression    mse  \n",
       "ames_housing                50.27      regression    mse  \n",
       "wine                        97.26  classification    mcc  \n",
       "phishing                    99.24  classification    mcc  \n",
       "mushroom                   100.00  classification    mcc  \n",
       "breast_cancer               98.67  classification    mcc  "
      ]
     },
     "execution_count": 665,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parity_small[grouping_simple_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RF(opt)vsRF(all)</th>\n",
       "      <th>GBDT(opt)vsGBDT(all)</th>\n",
       "      <th>task</th>\n",
       "      <th>metric</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>diabetes</th>\n",
       "      <td>106.24</td>\n",
       "      <td>91.94</td>\n",
       "      <td>regression</td>\n",
       "      <td>mse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crime</th>\n",
       "      <td>106.90</td>\n",
       "      <td>116.61</td>\n",
       "      <td>regression</td>\n",
       "      <td>mse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boston</th>\n",
       "      <td>84.45</td>\n",
       "      <td>108.77</td>\n",
       "      <td>regression</td>\n",
       "      <td>mse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ames_housing</th>\n",
       "      <td>103.24</td>\n",
       "      <td>110.52</td>\n",
       "      <td>regression</td>\n",
       "      <td>mse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wine</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>classification</td>\n",
       "      <td>mcc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phishing</th>\n",
       "      <td>100.52</td>\n",
       "      <td>100.59</td>\n",
       "      <td>classification</td>\n",
       "      <td>mcc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mushroom</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>classification</td>\n",
       "      <td>mcc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breast_cancer</th>\n",
       "      <td>102.61</td>\n",
       "      <td>100.00</td>\n",
       "      <td>classification</td>\n",
       "      <td>mcc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               RF(opt)vsRF(all)  GBDT(opt)vsGBDT(all)            task metric\n",
       "dataset                                                                     \n",
       "diabetes                 106.24                 91.94      regression    mse\n",
       "crime                    106.90                116.61      regression    mse\n",
       "boston                    84.45                108.77      regression    mse\n",
       "ames_housing             103.24                110.52      regression    mse\n",
       "wine                     100.00                100.00  classification    mcc\n",
       "phishing                 100.52                100.59  classification    mcc\n",
       "mushroom                 100.00                100.00  classification    mcc\n",
       "breast_cancer            102.61                100.00  classification    mcc"
      ]
     },
     "execution_count": 666,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parity_small[grouping_complex_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parity_small.to_csv('results_coalition_parity/parity_small.csv')\n",
    "\n",
    "# parity_large.to_csv('results_coalition_parity/parity_large.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
